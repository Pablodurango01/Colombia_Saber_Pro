{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pchy5KZfJS31",
        "outputId": "0d96a6c2-068f-4063-ac6c-7dd7ac80281e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.9/2.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q lightgbm==3.3.5 category_encoders scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from category_encoders import TargetEncoder\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "nFuKI8qSJivs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BASE_DIR = '/content/drive/MyDrive/ai_data'\n",
        "train = pd.read_csv(f\"{BASE_DIR}/train.csv\")\n",
        "test  = pd.read_csv(f\"{BASE_DIR}/test.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU9oG2MnJl-b",
        "outputId": "4e0f797d-55c3-4a4e-a6ac-98b068378ec6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape:\", train.shape)\n",
        "print(train['RENDIMIENTO_GLOBAL'].value_counts(normalize=True))\n",
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdlqzZD2Jukc",
        "outputId": "1a83177c-0dce-4c37-fb59-7d7e3abf3d43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (692500, 21)\n",
            "RENDIMIENTO_GLOBAL\n",
            "alto          0.253601\n",
            "bajo          0.249801\n",
            "medio-bajo    0.248773\n",
            "medio-alto    0.247825\n",
            "Name: proportion, dtype: float64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 692500 entries, 0 to 692499\n",
            "Data columns (total 21 columns):\n",
            " #   Column                          Non-Null Count   Dtype  \n",
            "---  ------                          --------------   -----  \n",
            " 0   ID                              692500 non-null  int64  \n",
            " 1   PERIODO                         692500 non-null  int64  \n",
            " 2   ESTU_PRGM_ACADEMICO             692500 non-null  object \n",
            " 3   ESTU_PRGM_DEPARTAMENTO          692500 non-null  object \n",
            " 4   ESTU_VALORMATRICULAUNIVERSIDAD  686213 non-null  object \n",
            " 5   ESTU_HORASSEMANATRABAJA         661643 non-null  object \n",
            " 6   FAMI_ESTRATOVIVIENDA            660363 non-null  object \n",
            " 7   FAMI_TIENEINTERNET              665871 non-null  object \n",
            " 8   FAMI_EDUCACIONPADRE             669322 non-null  object \n",
            " 9   FAMI_TIENELAVADORA              652727 non-null  object \n",
            " 10  FAMI_TIENEAUTOMOVIL             648877 non-null  object \n",
            " 11  ESTU_PRIVADO_LIBERTAD           692500 non-null  object \n",
            " 12  ESTU_PAGOMATRICULAPROPIO        686002 non-null  object \n",
            " 13  FAMI_TIENECOMPUTADOR            654397 non-null  object \n",
            " 14  FAMI_TIENEINTERNET.1            665871 non-null  object \n",
            " 15  FAMI_EDUCACIONMADRE             668836 non-null  object \n",
            " 16  RENDIMIENTO_GLOBAL              692500 non-null  object \n",
            " 17  coef_1                          692500 non-null  float64\n",
            " 18  coef_2                          692500 non-null  float64\n",
            " 19  coef_3                          692500 non-null  float64\n",
            " 20  coef_4                          692500 non-null  float64\n",
            "dtypes: float64(4), int64(2), object(15)\n",
            "memory usage: 111.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'RENDIMIENTO_GLOBAL'\n",
        "ID_COL = 'ID'\n",
        "\n",
        "# Unir train/test para procesamiento\n",
        "full = pd.concat([train.assign(_is_train=1), test.assign(_is_train=0)], axis=0)\n",
        "\n",
        "# Identificar columnas\n",
        "cat_cols = full.select_dtypes(include=['object']).columns.drop([TARGET])\n",
        "num_cols = full.select_dtypes(include=[np.number]).columns.drop([ID_COL, '_is_train'])\n",
        "\n",
        "# Ajustar TargetEncoder solo con datos sin NaN en TARGET\n",
        "tencoder = TargetEncoder(cols=cat_cols)\n",
        "train_mask = full['_is_train'] == 1\n",
        "# Entrenar encoder con datos de train\n",
        "tencoder.fit(full.loc[train_mask, cat_cols], full.loc[train_mask, TARGET])\n",
        "# Aplicar transform tanto a train como a test\n",
        "full_cat = tencoder.transform(full[cat_cols])\n",
        "\n",
        "# Imputación simple de numéricos\n",
        "imp = SimpleImputer(strategy='median')\n",
        "full_num = pd.DataFrame(\n",
        "    imp.fit_transform(full[num_cols]),\n",
        "    columns=num_cols,\n",
        "    index=full.index\n",
        ")\n",
        "\n",
        "# Combinamos ID, indicador y columnas procesadas\n",
        "df_proc = pd.concat([\n",
        "    full[[ID_COL, TARGET, '_is_train']].reset_index(drop=True),\n",
        "    full_cat.reset_index(drop=True),\n",
        "    full_num.reset_index(drop=True)\n",
        "], axis=1)\n",
        "# Eliminamos indicador temporal\n",
        "df_proc.drop(columns=['_is_train'], inplace=True)\n",
        "# %%\n",
        "# 10. Reconstruir sets y preparar modelo para submission\n",
        "# Reconstruir conjuntos de train/test\n",
        "df_train = df_proc[df_proc[TARGET].notna()].copy()\n",
        "df_test  = df_proc[df_proc[TARGET].isna()].copy().drop(columns=[TARGET])\n",
        "\n",
        "# Mapear etiquetas a enteros y back\n",
        "y_map = {'bajo':0, 'medio-bajo':1, 'medio-alto':2, 'alto':3}\n",
        "inv_y = {v:k for k,v in y_map.items()}\n",
        "\n",
        "# Features y target\n",
        "X = df_train.drop(columns=[ID_COL, TARGET])\n",
        "y = df_train[TARGET].map(y_map)\n",
        "X_test = df_test.drop(columns=[ID_COL], errors='ignore')"
      ],
      "metadata": {
        "id": "rsvZc3PSJ1zM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Entrenamiento LightGBM sobre todo el train\n",
        "from lightgbm import LGBMClassifier\n",
        "model_lgb = LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=31,\n",
        "    random_state=42\n",
        ")\n",
        "model_lgb.fit(X, y)\n",
        "print('✅ Model_lgb entrenado sobre todo el train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMDNrFFDLaOs",
        "outputId": "4379e08d-292a-48f0-b80f-c280e9ad6134"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model_lgb entrenado sobre todo el train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred = model_lgb.predict(X_test)\n",
        "sub = pd.DataFrame({\n",
        "    ID_COL: test[ID_COL],\n",
        "    TARGET: [inv_y[int(i)] for i in final_pred]\n",
        "})\n",
        "sub.to_csv(f\"{BASE_DIR}/submission_alternative.csv\", index=False)\n",
        "print(\"✅ Submission saved en submission_alternative.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jI8wm4yM7TC",
        "outputId": "eda5ea97-6192-4e7e-fe96-871084a09755"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submission saved en submission_alternative.csv\n"
          ]
        }
      ]
    }
  ]
}